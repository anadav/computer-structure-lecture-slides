\documentclass[aspectratio=169,12pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{hyperref}
\usepackage{makecell}
\usepackage{ragged2e}
\usepackage{bytefield}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric, calc, tikzmark, shapes.misc}
\usepackage{tikz-timing}
\usepackage{tcolorbox}

\usetheme{Madrid}
\usecolortheme{default}

% Custom colors
\definecolor{mygreen}{RGB}{0,128,0}
\definecolor{myblue}{RGB}{0,0,255}
\definecolor{myred}{RGB}{255,0,0}

\title{System}
\author{Computer Architecture 2360267}
\date{2025, Lecture \#5}

% Clock macro - draws a clock at given location
\newcommand{\drawclock}[1]{
    \begin{scope}[shift={(#1)}]
        \draw[thick] (0,0) circle (0.12);
        \draw[thick] (0,0) -- (0,0.08);
        \draw[thick] (0,0) -- (0.05,-0.03);
    \end{scope}
}

\begin{document}

\frame{\titlepage}

% Table of Contents
\begin{frame}{Outline}
\tableofcontents
\end{frame}

\section{CPU Architecture Overview}

% Slide 1: Core vs Uncore
\begin{frame}{CPU Architecture: Core vs Uncore}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Core (Execution Core):}
\begin{itemize}
\item The actual processing unit
\item Contains:
  \begin{itemize}
  \item ALUs, FPU
  \item Registers
  \item L1 cache (I\$ + D\$)
  \item Usually L2 cache (private)
  \item Branch predictor
  \item Decode/dispatch units
  \end{itemize}
\item Each core can run 1-2 threads (with SMT/HT)
\item The part that executes instructions
\end{itemize}

\column{0.5\textwidth}
\textbf{Uncore (System Agent):}
\begin{itemize}
\item Everything else on the chip
\item Contains:
  \begin{itemize}
  \item Memory controllers
  \item Last Level Cache (LLC/L3)
  \item PCIe controllers
  \item Interconnect (ring/mesh)
  \item Power management
  \item Integrated GPU (if present)
  \end{itemize}
\item Shared by all cores
\item Runs at different frequency (often lower)
\end{itemize}
\end{columns}

\vspace{0.3cm}
\begin{center}
\begin{tikzpicture}[scale=0.8]
\draw[thick, dashed] (0,0) rectangle (7,3);
\node at (3.5,2.7) {\textbf{CPU Die}};

% Cores
\foreach \x in {0.5,1.5,2.5} {
    \draw[fill=blue!30] (\x,1.5) rectangle (\x+0.8,2.3);
    \node at (\x+0.4,1.9) {\tiny Core};
}

% Uncore components
\draw[fill=green!30] (4,1.5) rectangle (6.5,2.3);
\node at (5.25,1.9) {\small Uncore};
\draw[fill=gray!30] (0.5,0.5) rectangle (3.3,1.2);
\node at (1.9,0.85) {\small L3 Cache};
\draw[fill=orange!30] (4,0.5) rectangle (5,1.2);
\node at (4.5,0.85) {\tiny MC};
\draw[fill=purple!30] (5.2,0.5) rectangle (6.5,1.2);
\node at (5.85,0.85) {\tiny PCIe/IO};
\end{tikzpicture}
\end{center}
\end{frame}

% Slide 2: Tile Architecture
\begin{frame}{Tile Architecture}
\textbf{Tile}: A modular, repeatable unit in modern CPUs

\begin{columns}[T]
\column{0.5\textwidth}
\textbf{What's in a Tile:}
\begin{itemize}
\item One or two cores
\item Private L2 cache
\item Slice of shared L3 cache
\item Portion of the interconnect
\item Local routing/control logic
\end{itemize}

\vspace{0.3cm}
\textbf{Why Tiles?}
\begin{itemize}
\item Modular design (copy-paste)
\item Easier to scale (add more tiles)
\item Better yield (disable bad tiles)
\item Consistent layout for manufacturing
\end{itemize}

\column{0.5\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.9]
% Single tile detail
\draw[ultra thick] (0,0) rectangle (2,2.5);
\node at (1,2.2) {\textbf{Tile}};
\draw[fill=blue!30] (0.2,1.5) rectangle (0.9,2);
\node at (0.55,1.75) {\tiny Core};
\draw[fill=blue!30] (1.1,1.5) rectangle (1.8,2);
\node at (1.45,1.75) {\tiny Core};
\draw[fill=yellow!30] (0.2,0.9) rectangle (1.8,1.3);
\node at (1,1.1) {\tiny L2 Cache};
\draw[fill=green!30] (0.2,0.3) rectangle (1.8,0.7);
\node at (1,0.5) {\tiny L3 Slice};
\draw[fill=red!20] (0.2,0.05) rectangle (1.8,0.25);
\node at (1,0.15) {\tiny Ring Stop};

\node at (1,-0.5) {\small Single Tile};

% Multiple tiles
\begin{scope}[shift={(3,0)}]
\foreach \x in {0,1.5} {
    \foreach \y in {0,1.3} {
        \draw[thick] (\x,\y) rectangle (\x+1.3,\y+1);
        \draw[fill=blue!20] (\x+0.1,\y+0.6) rectangle (\x+0.6,\y+0.9);
        \draw[fill=green!20] (\x+0.1,\y+0.1) rectangle (\x+1.2,\y+0.4);
    }
}
\draw[red, thick] (0.65,0) -- (0.65,2.3);
\draw[red, thick] (1.5+0.65,0) -- (1.5+0.65,2.3);
\draw[red, thick] (0,0.5) -- (2.8,0.5);
\draw[red, thick] (0,1.8) -- (2.8,1.8);
\node at (1.4,-0.5) {\small 4-Tile Mesh};
\end{scope}
\end{tikzpicture}
\end{center}

\textbf{Examples:}
\begin{itemize}
\item Intel Skylake-SP: Tiles in mesh
\item Intel Lakefield: Big + small tiles
\item Modern server CPUs: 10-40 tiles
\end{itemize}
\end{columns}
\end{frame}

% Slide 3: Die and Multi-Die Designs
\begin{frame}{Die and Multi-Die Designs}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{Die (Silicon Die):}
\begin{itemize}
\item Single piece of silicon
\item Cut from a wafer
\item Contains transistors/circuits
\item Traditional: 1 die = 1 CPU
\end{itemize}

\vspace{0.3cm}
\textbf{Monolithic Die:}
\begin{itemize}
\item Everything on one die
\item Simpler, lower latency
\item More expensive (yield)
\item Size limited by manufacturing
\end{itemize}

\vspace{0.3cm}
\textbf{Multi-Die (Chiplet):}
\begin{itemize}
\item Multiple smaller dies
\item Connected in package
\item Better yield, mix-and-match
\item Higher latency between dies
\end{itemize}

\column{0.55\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.75]
% Monolithic
\draw[thick] (0,0) rectangle (3,2.5);
\node at (1.5,2.2) {\textbf{Monolithic}};
\foreach \x in {0.3,0.9,1.5,2.1} {
    \draw[fill=blue!30] (\x,1.5) rectangle (\x+0.4,1.9);
}
\draw[fill=green!30] (0.3,0.8) rectangle (2.7,1.2);
\node at (1.5,1) {\tiny L3 Cache};
\draw[fill=orange!30] (0.3,0.3) rectangle (1.4,0.6);
\node at (0.85,0.45) {\tiny MC};
\draw[fill=purple!30] (1.6,0.3) rectangle (2.7,0.6);
\node at (2.15,0.45) {\tiny I/O};
\node at (1.5,-0.3) {\small Intel Core i7};

% Chiplet design
\begin{scope}[shift={(4.5,0)}]
% CCD 1
\draw[thick, fill=blue!10] (0,1.3) rectangle (1.3,2.5);
\node at (0.65,2.2) {\tiny CCD};
\foreach \x in {0.1,0.7} {
    \foreach \y in {1.4,1.8} {
        \draw[fill=blue!30] (\x,\y) rectangle (\x+0.4,\y+0.3);
    }
}

% CCD 2
\draw[thick, fill=blue!10] (1.5,1.3) rectangle (2.8,2.5);
\node at (2.15,2.2) {\tiny CCD};
\foreach \x in {1.6,2.2} {
    \foreach \y in {1.4,1.8} {
        \draw[fill=blue!30] (\x,\y) rectangle (\x+0.4,\y+0.3);
    }
}

% IOD
\draw[thick, fill=orange!10] (0,0) rectangle (2.8,1.1);
\node at (1.4,0.8) {\small I/O Die};
\draw[fill=orange!30] (0.2,0.3) rectangle (1.2,0.6);
\node at (0.7,0.45) {\tiny MC};
\draw[fill=purple!30] (1.6,0.3) rectangle (2.6,0.6);
\node at (2.1,0.45) {\tiny PCIe};

% Connections
\draw[<->, red, thick] (0.65,1.3) -- (0.65,1.1);
\draw[<->, red, thick] (2.15,1.3) -- (2.15,1.1);

\node at (1.4,-0.3) {\small AMD Ryzen};
\end{scope}
\end{tikzpicture}
\end{center}

\textbf{Advantages of Chiplets:}
\begin{itemize}
\item Mix different process nodes (7nm compute, 14nm I/O)
\item Reuse dies across products
\item Better yields (smaller dies)
\end{itemize}
\end{columns}
\end{frame}

% Slide 4: Package and Socket
\begin{frame}{Package and Socket}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Package:}
\begin{itemize}
\item Physical chip you can hold
\item Contains:
  \begin{itemize}
  \item One or more dies
  \item Substrate (PCB)
  \item Heat spreader (IHS)
  \item Pins/pads for connection
  \end{itemize}
\item Protects silicon
\item Provides electrical connections
\end{itemize}

\vspace{0.3cm}
\textbf{Socket:}
\begin{itemize}
\item Receptacle on motherboard
\item Holds the package
\item Examples: LGA1700, AM5, SP3
\item Defines:
  \begin{itemize}
  \item Pin count and layout
  \item Power delivery
  \item Memory channels
  \end{itemize}
\end{itemize}

\column{0.5\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.8]
% Cross-section view
\node at (0,3.5) {\textbf{Package Cross-Section}};

% IHS
\draw[fill=gray!50] (-2,2) rectangle (2,2.5);
\node at (0,2.25) {\small IHS (Heat Spreader)};

% Die
\draw[fill=blue!30] (-1,1.3) rectangle (1,1.8);
\node at (0,1.55) {\small Die};

% Substrate
\draw[fill=green!30] (-2.5,0.5) rectangle (2.5,1.2);
\node at (0,0.85) {\small Substrate};

% Pins
\foreach \x in {-2,-1.5,-1,-0.5,0,0.5,1,1.5,2} {
    \draw[thick] (\x,0.5) -- (\x,0.2);
}
\node at (0,0) {\small Pins/Pads};

% Socket representation
\draw[ultra thick] (-3,-0.5) rectangle (3,-0.2);
\node at (0,-0.7) {\small Socket};

% Motherboard
\draw[fill=green!60] (-3.5,-1.5) rectangle (3.5,-0.9);
\node at (0,-1.2) {\small Motherboard};

\draw[<->, thick] (2.7,2.25) -- (2.7,-0.35) node[midway, right] {\small Package};
\end{tikzpicture}
\end{center}

\textbf{Multi-Socket Systems:}
\begin{itemize}
\item 2S, 4S, 8S (S = Socket)
\item Each socket = independent CPU
\item Connected via UPI/IF
\item Creates NUMA topology
\end{itemize}
\end{columns}
\end{frame}

% Slide 5: Putting It All Together
\begin{frame}{Hierarchy: From Transistor to System}
\begin{center}
\begin{tikzpicture}[scale=0.75,
    level/.style={draw, thick, minimum width=2.5cm, minimum height=0.8cm}
]

% Hierarchy levels
\node[level, fill=red!20] (trans) at (0,0) {Transistors};
\node[level, fill=orange!20] (core) at (0,1.2) {Core};
\node[level, fill=yellow!20] (tile) at (0,2.4) {Tile};
\node[level, fill=green!20] (die) at (0,3.6) {Die};
\node[level, fill=blue!20] (package) at (0,4.8) {Package};
\node[level, fill=purple!20] (system) at (0,6) {System};

% Descriptions
\node[text width=6cm, anchor=west] (trans_disc) at ([xshift=12]trans.east) {\small Billions of switches\\ (5-10nm process)};
\node[text width=6cm, anchor=west] at (trans_disc.west |- core) {\small Execution unit + L1/L2\\ (1-2 threads)};
\node[text width=6cm, anchor=west] at (trans_disc.west |- tile) {\small Core(s) + L3 slice + interconnect\\ (modular unit)};
\node[text width=6cm, anchor=west] at (trans_disc.west |- die) {\small Complete silicon chip\\ (monolithic or chiplet)};
\node[text width=6cm, anchor=west] at (trans_disc.west |- package) {\small Die(s) + substrate + pins\\ (what goes in socket)};
\node[text width=6cm, anchor=west] at (trans_disc.west |- system) {\small Multiple sockets + memory + I/O\\ (complete computer)};

% Examples on left
\node[text width=6cm, anchor=east] (trans_example) at ([xshift=-12]trans.east) {\small \textit{7nm = 10M+/mm²}};
\node[text width=6cm, anchor=east] at (trans_example.east |- core) {\small \textit{Golden Cove, Zen 4}};
\node[text width=6cm, anchor=east] at (trans_example.east |- tile) {\small \textit{2-core tile}};
\node[text width=6cm, anchor=east] at (trans_example.east |- die) {\small \textit{CCD, Alder Lake die}};
\node[text width=6cm, anchor=east] at (trans_example.east |- package) {\small \textit{Xeon, EPYC, Core i9}};
\node[text width=6cm, anchor=east] at (trans_example.east |- system) {\small \textit{2S server, workstation}};

% Arrows
\foreach \i in {0,1,2,3,4} {
    \draw[->, thick] (0,\i*1.2+0.4) -- (0,\i*1.2+0.8);
}

\end{tikzpicture}
\end{center}

\textbf{Key Insight:} Each level has its own interconnect needs:
\begin{itemize}
\item Within core: Register bypass networks
\item Within tile: L2-L3 connections
\item Within die: Ring/mesh/crossbar
\item Within package: Die-to-die (chiplets)
\item Between packages: UPI/IF (NUMA)
\end{itemize}
\end{frame}

% Slide 6: Modern Examples
\begin{frame}{Modern CPU Examples}
\begin{center}
\footnotesize
\begin{tabular}{l|c|c|c|c}
\toprule
\textbf{CPU} & \textbf{Cores/Die} & \textbf{Dies/Pkg} & \textbf{Interconnect} & \textbf{Notes} \\
\midrule
Intel Core i9-13900K & 24 (8P+16E) & 1 & Ring + Fabric & Monolithic \\
Intel Xeon Platinum & up to 40 & 1 & Mesh & Monolithic, tiles \\
\midrule
AMD Ryzen 9 7950X & 16 & 2 CCD + 1 IOD & IF (intra \& inter) & Chiplet \\
AMD EPYC 9654 & 96 & 12 CCD + 1 IOD & IF & Massive chiplet \\
\midrule
Apple M2 Ultra & 24 & 2 & UltraFusion & Die-to-die bridge \\
\midrule
Intel Sapphire Rapids & up to 60 & 4 & EMIB bridges & Multi-tile \\
\bottomrule
\end{tabular}
\end{center}

\vspace{0.5cm}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Monolithic Advantages:}
\begin{itemize}
\item Lower latency
\item Simpler software model
\item No die-to-die overhead
\end{itemize}

\column{0.5\textwidth}
\textbf{Multi-Die Advantages:}
\begin{itemize}
\item Higher core counts
\item Better yields
\item Mix-and-match configs
\item Reusable components
\end{itemize}
\end{columns}

\vspace{0.3cm}
\textbf{Software must adapt to these different architectures for optimal performance!}
\end{frame}


\section{Interconnects and Multi-Core Systems}

% Slide 1: Modern CPU Architecture Overview
\begin{frame}{Modern Multi-Core CPU Architecture}
\begin{columns}[T]
\column{0.55\textwidth}
\textbf{Hierarchy of Components:}
\begin{enumerate}
\item \textbf{Core}: Execution units + L1/L2 cache
\item \textbf{Socket/Package}: Multiple cores + shared L3 + memory controller
\item \textbf{System}: Multiple sockets + memory
\end{enumerate}

\vspace{0.3cm}
\textbf{Two Types of Interconnects:}
\begin{itemize}
\item \textcolor{blue}{\textbf{Intra-socket}}: Connects cores within CPU
\item \textcolor{red}{\textbf{Inter-socket}}: Connects different CPUs
\end{itemize}

\column{0.45\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.75]
% Socket box
\draw[thick, dashed] (-0.5,-0.5) rectangle (4.5,4.5);
\node at (2,4.2) {\textbf{CPU Socket}};

% Cores
\foreach \x in {0,1} {
    \foreach \y in {0,1} {
        \pgfmathtruncatemacro{\cnum}{\x*2+\y}
        \draw[fill=blue!30] (\x*2,\y*2+1.5) rectangle (\x*2+0.8,\y*2+2.3);
        \node at (\x*2+0.4,\y*2+1.9) {\tiny Core \cnum};
        \draw[fill=yellow!30] (\x*2+0.9,\y*2+1.5) rectangle (\x*2+1.5,\y*2+2.3);
        \node at (\x*2+1.2,\y*2+1.9) {\tiny L2};
    }
}

% Shared L3
\draw[fill=green!30] (0.5,0.5) rectangle (3.5,1);
\node at (2,0.75) {Shared L3 Cache};

% Memory Controller
\draw[fill=orange!30] (0,0) rectangle (1.5,0.3);
\node at (0.75,0.15) {\tiny Mem Ctrl};

% Ring interconnect
\draw[thick, blue, <->] (0.4,1.5) -- (0.4,1.2);
\draw[thick, blue, <->] (2.4,1.5) -- (2.4,1.2);
\draw[thick, blue, <->] (0.4,3.5) -- (0.4,3.8);
\draw[thick, blue, <->] (2.4,3.5) -- (2.4,3.8);
\draw[thick, blue] (0.4,1.2) -- (2.4,1.2);
\draw[thick, blue] (0.4,3.8) -- (2.4,3.8);
\draw[thick, blue] (0.4,1.2) -- (0.4,3.8);
\draw[thick, blue] (2.4,1.2) -- (2.4,3.8);
\node[blue] at (1.4,2.5) {\tiny Ring};

\end{tikzpicture}
\end{center}
\end{columns}
\end{frame}

% Slide 2: Intra-Socket Interconnects
\begin{frame}{Intra-Socket Interconnects}
Connect cores, caches, memory controllers, and I/O within a single CPU package

\begin{center}
\begin{tikzpicture}[scale=0.65,
    core/.style={draw, rectangle, fill=blue!30, minimum width=0.6cm, minimum height=0.5cm},
    cache/.style={draw, rectangle, fill=green!30, minimum width=2.5cm, minimum height=0.3cm},
    mc/.style={draw, rectangle, fill=orange!30, minimum width=0.8cm, minimum height=0.3cm}
]

% Ring Topology
\begin{scope}[shift={(-5,0)}]
\node at (0, 2) {\textbf{Ring Bus}};
\node at (0, 1.5) {\footnotesize (Intel Core, Xeon E5)};
% Draw ring
\draw[thick, blue] (0,0) circle (1cm);
% Add components with L3 slices
\foreach \i/\angle in {0/90, 1/0, 2/270, 3/180} {
    \node[core] (c\i) at (\angle:1) {\tiny C\i};
    \node[cache, minimum width=0.3cm] at (\angle:0.65) {\tiny L3};
}
\node[mc] (ring_mc) at (0,-2) {\tiny MC};
\draw[<->, thick] (c2) -- (ring_mc.north);

% Annotations
\node[text width=5cm, align=left] at (0,-4.2) {
\footnotesize
• Bidirectional ring\\
• Each core has L3 slice\\
• Low latency (5-12 hops)\\
• Limited to ~10 cores
};
\end{scope}

% Mesh Topology
\begin{scope}[shift={(2.5,0)}]
\node at (0, 2) {\textbf{Mesh}};
\node at (0, 1.5) {\footnotesize (Intel Xeon SP)};
% Draw mesh with integrated L3
\foreach \x in {-1,0,1} {
    \foreach \y in {-1,0,1} {
        \node[core] (m\x\y) at (\x*0.7,\y*0.7) {\tiny};
        \node[cache, minimum width=0.25cm, minimum height=0.15cm] at (\x*0.7+0.15,\y*0.7-0.15) {\tiny};
    }
}
% Draw connections
\foreach \x in {-1,0,1} {
    \draw[blue, thick] (\x*0.7,-1*0.7) -- (\x*0.7,1*0.7);
}
\foreach \y in {-1,0,1} {
    \draw[blue, thick] (-1*0.7,\y*0.7) -- (1*0.7,\y*0.7);
}
\node[mc] (mesh_mc1) at (-0.7,-2) {\tiny MC};
\node[mc] (mesh_mc2) at (0.7,-2) {\tiny MC};
\draw[<->, thick] (m-1-1) -- (mesh_mc1.north);
\draw[<->, thick] (m1-1) -- (mesh_mc2.north);

% Annotations
\node[text width=5cm, align=left] at (0,-4.2) {
\footnotesize
• 2D grid topology\\
• Each tile: core + L3 slice\\
• Multiple MCs at edges\\
• Better bandwidth \& scaling
};
\end{scope}

% Crossbar/IF
\begin{scope}[shift={(10,0)}]
\node at (0, 2) {\textbf{Infinity Fabric}};
\node at (0, 1.5) {\footnotesize (AMD Zen)};

% CCX 0
\begin{scope}[shift={(-1.2,0)}]
\draw[dashed, thick] (-0.8,-0.8) rectangle (0.8,0.8);
\foreach \i in {0,1,2,3} {
    \node[core] (z0\i) at ({45+\i*90}:0.45) {\tiny};
}
\node[cache, minimum width=0.8cm, minimum height=0.2cm] at (0,-0.5) {\tiny L3};
\node at (0,0) {\tiny CCX0};
\end{scope}

% CCX 1
\begin{scope}[shift={(1.2,0)}]
\draw[dashed, thick] (-0.8,-0.8) rectangle (0.8,0.8);
\foreach \i in {0,1,2,3} {
    \node[core] (z1\i) at ({45+\i*90}:0.45) {\tiny};
}
\node[cache, minimum width=0.8cm, minimum height=0.2cm] at (0,-0.5) {\tiny L3};
\node at (0,0) {\tiny CCX1};
\end{scope}

% Infinity Fabric interconnect
\draw[<->, ultra thick, red] (-0.4,0) -- node[above, font=\tiny] {IF} (0.4,0);

% Memory controller
\node[mc] (ifmc) at (0,-2) {\tiny MC};
\draw[<->, thick] (-1.2,-0.8) |- (ifmc.west);
\draw[<->, thick] (1.2,-0.8) |- (ifmc.east);

% Annotations
\node[text width=5cm, align=left] at (0,-4.2) {
\footnotesize
• 4 cores + L3 per CCX\\
• IF connects CCXs\\
• Shared MC\\
• Low latency within CCX
};
\end{scope}

\end{tikzpicture}
\end{center}

All cores can access all cache and memory controllers, but with varying latency
\end{frame}

% Slide 3: Ring Interconnect Details
\begin{frame}{Ring Interconnect: How It Works}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Ring Architecture:}
\begin{itemize}
\item Bidirectional rings (clockwise + counter-clockwise)
\item Each "stop" contains:
  \begin{itemize}
  \item CPU core
  \item L3 cache slice
  \item Connection logic
  \end{itemize}
\item Messages take shortest path
\item Typically 32-byte data ring
\end{itemize}

\vspace{0.3cm}
\textbf{Why Rings Work Well (up to a point):}
\begin{itemize}
\item Simple to implement
\item Predictable latency
\item Good bandwidth for small core counts
\item Power efficient
\end{itemize}

\column{0.5\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.9]
% Draw ring stops
\foreach \i/\name in {0/Core0, 1/Core1, 2/Core2, 3/Core3, 4/LLC, 5/MC} {
    \pgfmathsetmacro{\angle}{90-\i*60}
    \coordinate (stop\i) at (\angle:1.5);
    \draw[fill=blue!20] (\angle:1.5) circle (0.3);
    \node at (\angle:2.1) {\tiny \name};
}

% Draw ring connections
\foreach \i in {0,...,5} {
    \pgfmathtruncatemacro{\next}{mod(\i+1,6)}
    \pgfmathsetmacro{\angle}{90-\i*60}
    \pgfmathsetmacro{\nextangle}{90-\next*60}
    \draw[->, thick, blue] (\angle:1.5) ++({\angle-90}:0.3) arc ({\angle-90}:{\nextangle+90}:1.2);
    \draw[->, thick, red] (\angle:1.5) ++({\angle+90}:0.3) arc ({\angle+90}:{\nextangle-90}:1.8);
}

\node at (0,0) {\footnotesize Bidirectional};

% Example path
\draw[->, ultra thick, green, dashed] (90:1.8) arc (90:330:1.8);
\node[green] at (0,-2.5) {\tiny Core0 → LLC: 2 hops (shortest)};
\end{tikzpicture}
\end{center}

\textbf{Limitations:}
\begin{itemize}
\item Bandwidth shared by all stops
\item Latency grows with core count
\item Not suitable for >10-12 cores
\end{itemize}
\end{columns}
\end{frame}

% Slide 4: Inter-Socket Interconnects
\begin{frame}{Inter-Socket Interconnects}
\textbf{Connecting Multiple CPUs in a System}

\begin{center}
\begin{tikzpicture}[scale=0.8,
    socket/.style={draw, thick, fill=blue!10, minimum width=3cm, minimum height=2.5cm},
    memory/.style={draw, fill=gray!20, minimum width=2.5cm, minimum height=0.5cm}
]

% Two socket system
\node[socket] (cpu0) at (0,0) {};
\node at (0,0.7) {\small CPU 0};
\node at (0,0.2) {\tiny 16 cores};
\node at (0,-0.2) {\tiny Ring/Mesh};
\node[memory] (mem0) at (0,-2) {\small Memory 0};
\draw[<->, thick] (cpu0.south) -- (mem0.north);

\node[socket] (cpu1) at (5,0) {};
\node at (5,0.7) {\small CPU 1};
\node at (5,0.2) {\tiny 16 cores};
\node at (5,-0.2) {\tiny Ring/Mesh};
\node[memory] (mem1) at (5,-2) {\small Memory 1};
\draw[<->, thick] (cpu1.south) -- (mem1.north);

% Inter-socket link
\draw[<->, ultra thick, red] (cpu0.east) -- node[above] {\small UPI/IF} node[below] {\tiny 10.4-16 GT/s} (cpu1.west);

% Annotations
\node[draw, thick, fill=yellow!20, text width=7cm] at (2.5,-3.5) {
\textbf{Inter-Socket Links:}\\
• \textbf{Intel UPI}: Ultra Path Interconnect (formerly QPI)\\
• \textbf{AMD Infinity Fabric}: Connects dies/sockets\\
• Point-to-point, cache-coherent\\
• Creates NUMA effects
};

\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\textbf{Performance Impact:}
\begin{columns}[T]
\column{0.5\textwidth}
\begin{itemize}
\item Local memory: \textasciitilde80-100 ns
\item Remote memory: \textasciitilde120-150 ns
\end{itemize}
\column{0.5\textwidth}
\begin{itemize}
\item Cross-socket bandwidth: 20-40 GB/s
\item Local memory bandwidth: 50-100 GB/s
\end{itemize}
\end{columns}
\end{frame}

% Slide 5: Complete System View
\begin{frame}{Complete System View: From Core to System}
\begin{center}
\begin{tikzpicture}[scale=0.7,
    core/.style={draw, fill=blue!30, minimum width=0.4cm, minimum height=0.4cm},
    l3/.style={draw, fill=green!30, minimum width=0.3cm, minimum height=0.3cm}
]

% Socket 0
\draw[thick, dashed] (-1,-1) rectangle (3,3);
\node at (1,2.7) {\small \textbf{Socket 0}};

% Cores with ring
\foreach \i in {0,1,2,3} {
    \pgfmathsetmacro{\x}{1+cos(\i*90)}
    \pgfmathsetmacro{\y}{1+sin(\i*90)}
    \node[core] at (\x,\y) {\tiny C\i};
    \node[l3] at (\x*0.6+1,\y*0.6+1) {};
}
\draw[blue, thick] (1,1) circle (0.8);
\node[blue] at (1,0) {\tiny Ring};

% Socket 1
\draw[thick, dashed] (5,-1) rectangle (9,3);
\node at (7,2.7) {\small \textbf{Socket 1}};

% Cores with ring
\foreach \i in {0,1,2,3} {
    \pgfmathsetmacro{\x}{7+cos(\i*90)}
    \pgfmathsetmacro{\y}{1+sin(\i*90)}
    \node[core] at (\x,\y) {\tiny C\i};
    \node[l3] at (\x*0.6+7,\y*0.6+1) {};
}
\draw[blue, thick] (7,1) circle (0.8);
\node[blue] at (7,0) {\tiny Ring};

% Memory
\draw[fill=gray!20] (0,-2) rectangle (2,-1.5) node[pos=.5] {\tiny Memory 0};
\draw[fill=gray!20] (6,-2) rectangle (8,-1.5) node[pos=.5] {\tiny Memory 1};

% Connections
\draw[<->, thick] (1,-1) -- (1,-1.5);
\draw[<->, thick] (7,-1) -- (7,-1.5);
\draw[<->, ultra thick, red] (3,1) -- node[above] {\small UPI/QPI} (5,1);

% Latency table
\node at (4,-3) {\textbf{Access Latencies:}};
\begin{scope}[shift={(4,-4)}]
\draw (0,0) grid (3,2);
\node at (-0.5,1.5) {\tiny From};
\node at (-0.5,0.5) {\tiny S0};
\node at (-0.5,1) {\tiny S1};
\node at (0.5,1.7) {\tiny S0};
\node at (1.5,1.7) {\tiny S1};
\node at (2.5,1.7) {\tiny L3};
\node at (0.5,1.25) {\tiny Mem};
\node at (1.5,1.25) {\tiny Mem};
\node at (2.5,1.25) {\tiny (same)};
\node at (0.5,0.5) {\textbf{\tiny 80ns}};
\node at (1.5,0.5) {\tiny 140ns};
\node at (2.5,0.5) {\textbf{\tiny 40ns}};
\node at (0.5,0.05) {\tiny 140ns};
\node at (1.5,0.05) {\textbf{\tiny 80ns}};
\node at (2.5,0.05) {\textbf{\tiny 40ns}};
\end{scope}

\end{tikzpicture}
\end{center}

\textbf{Key Insights:}
\begin{itemize}
\item Intra-socket communication (ring/mesh) is fast: 5-15 cycles
\item Inter-socket communication (UPI/IF) is slower: 50+ cycles  
\item Memory access hierarchy: L3 cache → Local DRAM → Remote DRAM
\item Software must be aware of this hierarchy for optimal performance
\end{itemize}
\end{frame}

% Slide 6: Software Implications
\begin{frame}{Software Implications}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{What Software Developers Need to Know:}

\vspace{0.2cm}
\textbf{1. Cache Coherency}
\begin{itemize}
\item Maintained automatically
\item But costs performance
\item Worse across sockets
\end{itemize}

\vspace{0.2cm}
\textbf{2. Memory Allocation}
\begin{itemize}
\item First-touch policy
\item NUMA-aware allocation
\item Thread-local storage
\end{itemize}

\vspace{0.2cm}
\textbf{3. Thread Placement}
\begin{itemize}
\item Pin threads to cores
\item Keep related threads on same socket
\item Minimize cross-socket communication
\end{itemize}

\column{0.5\textwidth}
\textbf{Performance Tips:}

\begin{enumerate}
\item \textbf{Check your topology:}\\
   \texttt{lscpu -e} or \texttt{lstopo}
   
\item \textbf{Quick improvement:}\\
   \texttt{numactl --cpunodebind=0 ./app}
   
\item \textbf{For shared data:}\\
   Place on socket with most accessors
   
\item \textbf{For partitioned data:}\\
   Align partitions to NUMA nodes
\end{enumerate}

\vspace{0.3cm}
\begin{tikzpicture}
\node[draw, thick, fill=red!20, text width=5cm] at (0,0) {
\textbf{Remember:}\\
Remote memory access = 1.5-2x slower\\
Cross-socket atomics = 3-5x slower\\
False sharing across sockets = 10x slower
};
\end{tikzpicture}
\end{columns}
\end{frame}


\section{NUMA Architecture}

% Slide 1: Introduction to NUMA
\begin{frame}{From UMA to NUMA}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Uniform Memory Access (UMA)}
\begin{itemize}
\item All cores share single memory controller
\item Equal latency to all memory
\item Simple programming model
\item \textcolor{red}{Bottleneck}: Memory controller bandwidth
\end{itemize}

\column{0.52\textwidth}
\textbf{Non-Uniform Memory Access (NUMA)}
\begin{itemize}
\item Multiple memory controllers
\item Memory "local" to each CPU socket
\item Variable memory latency
\item Higher aggregate bandwidth
\item \textcolor{orange}{Challenge}: Data locality matters!
\end{itemize}
\end{columns}

\vspace{0.3cm}
\begin{center}
\begin{tikzpicture}[scale=0.7]
% UMA diagram
\draw[fill=blue!20] (-5.5,0) rectangle (-2.5,1) node[pos=.5] {CPU Cores};
\draw[fill=green!20] (-4.5,-1) rectangle (-3.5,-0.5) node[pos=.5, font=\tiny] {MC};
\draw[fill=gray!20] (-5.5,-2.5) rectangle (-2.5,-1.5) node[pos=.5] {Memory};
\draw[<->, thick] (-4,0) -- (-4,-0.5);
\draw[<->, thick] (-4,-1) -- (-4,-1.5);

% NUMA diagram
% Node 0
\draw[fill=blue!20] (-0.5,0) rectangle (1.5,1) node[pos=.5] {CPU 0};
\draw[fill=green!20] (0.3,-0.5) rectangle (0.7,-0.2) node[pos=.5, font=\tiny] {MC};
\draw[fill=gray!20] (-0.5,-1.5) rectangle (1.5,-1) node[pos=.5] {Memory 0};
\draw[<->, thick] (0.5,0) -- (0.5,-0.2);
\draw[<->, thick] (0.5,-0.5) -- (0.5,-1);

% Node 1
\draw[fill=blue!20] (2.5,0) rectangle (4.5,1) node[pos=.5] {CPU 1};
\draw[fill=green!20] (3.3,-0.5) rectangle (3.7,-0.2) node[pos=.5, font=\tiny] {MC};
\draw[fill=gray!20] (2.5,-1.5) rectangle (4.5,-1) node[pos=.5] {Memory 1};
\draw[<->, thick] (3.5,0) -- (3.5,-0.2);
\draw[<->, thick] (3.5,-0.5) -- (3.5,-1);

% Interconnect
\draw[<->, thick, red] (1.5,0.5) -- node[above, font=\tiny] {Interconnect} (2.5,0.5);
\end{tikzpicture}
\end{center}
\end{frame}

% Slide 2: NUMA Topology
\begin{frame}{NUMA Node Topology}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{Key Concepts:}
\begin{itemize}
\item \textbf{NUMA Node}: CPU cores + local memory
\item \textbf{Socket}: Physical CPU package
\item \textbf{Distance}: Relative memory access cost
\item \textbf{Affinity}: Binding threads/memory to nodes
\end{itemize}

\vspace{0.3cm}
\textbf{Typical 2-Socket System:}
\begin{itemize}
\item Local memory: \textasciitilde100 cycles
\item Remote memory: \textasciitilde150-200 cycles
\item Can be 50-100\% slower!
\end{itemize}

\column{0.55\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.8]
% NUMA Node 0
\draw[thick, fill=blue!10] (0,0) rectangle (3,3);
\node at (1.5, 2.7) {\small \textbf{NUMA Node 0}};
\foreach \x in {0.3,0.9,1.5,2.1} {
    \foreach \y in {1.8,2.3} {
        \draw[fill=blue!30] (\x,\y) rectangle (\x+0.4,\y+0.3);
    }
}
\node at (1.5, 2.05) {\tiny 8 cores};
\draw[fill=gray!30] (0.3,0.3) rectangle (2.7,1.3);
\node at (1.5,0.8) {32GB RAM};

% NUMA Node 1
\draw[thick, fill=green!10] (4,0) rectangle (7,3);
\node at (5.5, 2.7) {\small \textbf{NUMA Node 1}};
\foreach \x in {4.3,4.9,5.5,6.1} {
    \foreach \y in {1.8,2.3} {
        \draw[fill=green!30] (\x,\y) rectangle (\x+0.4,\y+0.3);
    }
}
\node at (5.5, 2.05) {\tiny 8 cores};
\draw[fill=gray!30] (4.3,0.3) rectangle (6.7,1.3);
\node at (5.5,0.8) {32GB RAM};

% Interconnect
\draw[<->, ultra thick, red] (3,1.5) -- node[above] {\small QPI/UPI} node[below] {\tiny 25.6 GB/s} (4,1.5);

% Distance matrix
\node at (3.5, -0.8) {\small \textbf{NUMA Distance Matrix:}};
\node at (2.5, -1.3) {\tiny node};
\node at (3.5, -1.3) {\tiny 0};
\node at (4.5, -1.3) {\tiny 1};
\node at (2.5, -1.7) {\tiny 0};
\node at (3.5, -1.7) {\tiny \textbf{10}};
\node at (4.5, -1.7) {\tiny 21};
\node at (2.5, -2.1) {\tiny 1};
\node at (3.5, -2.1) {\tiny 21};
\node at (4.5, -2.1) {\tiny \textbf{10}};
\end{tikzpicture}
\end{center}
\end{columns}
\end{frame}

% Slide 3: Interconnect Topologies
\begin{frame}{Interconnect Topologies}
\begin{center}
\begin{tikzpicture}[scale=0.65,
    cpu/.style={draw, circle, fill=blue!30, minimum size=0.8cm},
    mem/.style={draw, rectangle, fill=gray!30, minimum width=0.6cm, minimum height=0.4cm}
]

% Ring (Intel)
\begin{scope}[shift={(0,0)}]
\node at (0, 1.5) {\textbf{Ring (Intel Sandy Bridge+)}};
\foreach \i in {0,1,2,3} {
    \node[cpu] (c\i) at ({90-\i*90}:1) {\tiny C\i};
}
\foreach \i in {0,1,2,3} {
    \pgfmathtruncatemacro{\j}{mod(\i+1,4)}
    \draw[->, thick] (c\i) to[bend left=20] (c\j);
}
\node[mem] at (0,-1.8) {\tiny Mem};
\draw[<->, thick] (c2) -- (0,-1.4);
\node[text width=3cm, align=center] at (0,-2.5) {\tiny Bidirectional ring\\ Low latency\\ Limited scalability};
\end{scope}

% Mesh (Intel)
\begin{scope}[shift={(5,0)}]
\node at (0, 1.5) {\textbf{Mesh (Intel Skylake-SP)}};
\foreach \x in {0,1,2} {
    \foreach \y in {0,1} {
        \node[cpu] (m\x\y) at (\x*0.8-0.8,\y*0.8-0.4) {\tiny};
    }
}
% Horizontal connections
\foreach \y in {0,1} {
    \draw[<->, thick] (m00) -- (m10);
    \draw[<->, thick] (m10) -- (m20);
}
% Vertical connections
\foreach \x in {0,1,2} {
    \draw[<->, thick] (m\x0) -- (m\x1);
}
\node[mem] at (0,-1.8) {\tiny Mem};
\draw[<->, thick] (m10) -- (0,-1.4);
\node[text width=3cm, align=center] at (0,-2.5) {\tiny 2D grid\\ Good scalability\\ Higher latency};
\end{scope}

% Crossbar (AMD)
\begin{scope}[shift={(10,0)}]
\node at (0, 1.5) {\textbf{Crossbar (AMD Zen)}};
\foreach \i in {0,1,2,3} {
    \node[cpu] (x\i) at ({45+\i*90}:1.2) {\tiny};
}
% Full crossbar connections
\foreach \i in {0,1,2} {
    \foreach \j in {1,2,3} {
        \ifnum\i<\j
            \draw[-, thick, gray!50] (x\i) -- (x\j);
        \fi
    }
}
\node[mem] at (0,-1.8) {\tiny IF};
\draw[<->, thick] (x2) -- (0,-1.4);
\node[text width=3cm, align=center] at (0,-2.5) {\tiny All-to-all within CCX\\ Lowest latency\\ Limited to small clusters};
\end{scope}

\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\textbf{Software Impact:}
\begin{itemize}
\item Different topologies $\rightarrow$ different performance characteristics
\item Ring: predictable latency, but can saturate with many cores
\item Mesh: better for many-core scaling, but more variable latency
\item Crossbar: excellent for small core counts, used in AMD's CCX design
\end{itemize}
\end{frame}

% Slide 4: Software Implications
\begin{frame}{NUMA: Software Implications}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Performance Impact:}
\begin{itemize}
\item Remote memory access: 50-100\% slower
\item Cache coherency traffic across nodes
\item Memory bandwidth per node is limited
\item False sharing amplified across NUMA
\end{itemize}

\vspace{0.3cm}
\textbf{Common Issues:}
\begin{itemize}
\item Thread migration between nodes
\item Data allocated on "wrong" node
\item Unbalanced memory usage
\item Lock contention across nodes
\end{itemize}

\column{0.5\textwidth}
\textbf{Best Practices:}
\begin{enumerate}
\item \textbf{First-touch policy}: Allocate memory on the node that first accesses it
\item \textbf{Thread affinity}: Pin threads to specific cores/nodes
\item \textbf{Data partitioning}: Align data structures to NUMA boundaries
\item \textbf{NUMA-aware allocation}: Use \texttt{numa\_alloc\_onnode()}
\end{enumerate}

\vspace{0.3cm}
\textbf{Tools:}
\begin{itemize}
\item \texttt{numactl}: Control NUMA policy
\item \texttt{lstopo}: Visualize topology
\item \texttt{numastat}: Memory statistics
\item \texttt{perf}: Profile NUMA events
\end{itemize}
\end{columns}
\end{frame}

% Slide 5: NUMA Code Example
\begin{frame}[fragile]{NUMA-Aware Programming Example}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{NUMA-Unaware Code:}
\begin{tcolorbox}[colback=red!5!white, colframe=red!50!black, boxrule=0.5pt, left=1pt, right=1pt, top=1pt, bottom=1pt]
{\scriptsize
\begin{verbatim}
// Thread 0 allocates all data
float* data = malloc(N * sizeof(float));

// All threads access same array
#pragma omp parallel
{
  int tid = omp_get_thread_num();
  int chunk = N / num_threads;
  int start = tid * chunk;
  
  // Remote memory access!
  for(int i = start; i < start+chunk; i++)
    data[i] = compute(i);
}
\end{verbatim}
}
\end{tcolorbox}

\column{0.5\textwidth}
\textbf{NUMA-Aware Code:}
\begin{tcolorbox}[colback=green!5!white, colframe=green!50!black, boxrule=0.5pt, left=1pt, right=1pt, top=1pt, bottom=1pt]
{\scriptsize
\begin{verbatim}
#pragma omp parallel
{
  int tid = omp_get_thread_num();
  int chunk = N / num_threads;
  
  // Each thread allocates locally
  float* local_data = 
    numa_alloc_local(chunk * sizeof(float));
  
  // Access local memory only
  for(int i = 0; i < chunk; i++)
    local_data[i] = compute(tid*chunk + i);
    
  // Copy to global if needed
  memcpy(&data[tid*chunk], local_data, ...);
}
\end{verbatim}
}
\end{tcolorbox}
\end{columns}

\vspace{0.3cm}
\textbf{Performance difference can be 2-3x for memory-bound workloads!}
\end{frame}

% Slide 6: Practical NUMA Considerations
\begin{frame}{Practical NUMA Considerations}
\begin{columns}[T]
\column{0.55\textwidth}
\textbf{When NUMA Matters Most:}
\begin{itemize}
\item Large working sets ($>$ L3 cache)
\item Memory-bandwidth intensive apps
\item Multi-socket servers
\item Database systems
\item Scientific computing (HPC)
\item In-memory key-value stores
\end{itemize}

\vspace{0.3cm}
\textbf{Quick Checks:}
\begin{itemize}
\item \texttt{lscpu | grep NUMA} - see topology
\item \texttt{numactl --hardware} - detailed info
\item \texttt{likwid-topology} - visual layout
\end{itemize}

\column{0.45\textwidth}
\begin{center}
\begin{tikzpicture}[scale=0.8]
\node[text width=5cm, draw, thick] (rulethumb) at (0,0) {
\textbf{Rule of Thumb:}\\[0.2cm]
If your application:\\
• Uses $>$ 10GB memory\\
• Runs on $>$ 8 cores\\
• Is memory-bandwidth limited\\[0.2cm]
$\Rightarrow$ \textcolor{red}{Consider NUMA optimization}
};

\node[text width=5cm, draw, thick, fill=yellow!20, anchor=north] at ([yshift=-0.5cm]rulethumb.south) {
\textbf{Quick Win:}\\[0.1cm]
\texttt{numactl --interleave=all ./app}\\[0.1cm]
Spreads memory across all nodes\\
Often 20-30\% improvement!
};
\end{tikzpicture}
\end{center}
\end{columns}

\vspace{0.3cm}
\textbf{Modern Developments:}
\begin{itemize}
\item AMD Zen: Multiple NUMA nodes per socket (CCX/CCD design)
\item Intel Sub-NUMA Clustering (SNC): Divides socket into NUMA nodes
\item CXL: Enables memory pooling across systems
\end{itemize}
\end{frame}


\section{Memory Subsystem}

\begin{frame}{Basic DRAM chip}
\textbf{DRAM:} 2D array of memory cells
\vspace{-0.2cm}

\begin{center}
\begin{tikzpicture}[scale=0.8, transform shape,
    block/.style={draw, minimum width=1.8cm, minimum height=1cm, align=center},
    decoder/.style={draw, minimum width=1.8cm, minimum height=1.2cm, align=center},
    signal/.style={->, >=stealth, thick},
    label/.style={font=\small\bfseries}
]

% Origin point - move this to shift entire diagram
\coordinate (origin) at (0,25);

% Row Address Latch - positioned relative to origin
\node[block, text width=1.5cm, fill=purple!20] (rowlatch) at (origin) {row address latch};

% Column Address Latch - positioned relative to row latch
\node[block, text width=1.5cm, fill=olive!20] (collatch) at ([yshift=-2.5cm]rowlatch) {column address latch};

% Row Address decoder - positioned relative to row latch
\node[decoder, text width=1.5cm, fill=purple!20] (rowdecoder) at ([xshift=3.5cm]rowlatch) {row address decoder};

% Column decoder - positioned relative to column latch
\node[block, text width=1.5cm, fill=olive!20] (coldecoder) at ([xshift=8.5cm]collatch) {column decoder};

% Memory array - positioned relative to decoders
\coordinate (array_corner) at ([xshift=2cm, yshift=1.2cm]rowdecoder.east);
\draw[thick] (array_corner) rectangle ([xshift=4cm, yshift=-2.7cm]array_corner);
\foreach \x in {0.3,0.6,0.9,1.2,1.5,1.8,2.1,2.4,2.7,3,3.3,3.7} {
    \draw ([xshift=\x cm]array_corner) -- ([xshift=\x cm, yshift=-2.7cm]array_corner);
}
\foreach \y in {-0.3,-0.6,-0.9,-1.2,-1.5,-1.8,-2.1,-2.4} {
    \draw ([yshift=\y cm]array_corner) -- ([xshift=4cm, yshift=\y cm]array_corner);
}

% Input signals - positioned relative to latches
\node[label, purple] (ras) at ([xshift=-3cm, yshift=0.3cm]rowlatch.west) {RAS$\#$};
\draw[signal, purple] (ras) -- (ras -| rowlatch.west);

\node[label, olive] (cas) at ([xshift=-3cm, yshift=-0.3cm]collatch.west) {CAS$\#$};
\draw[signal, olive] (cas) -- (cas -| collatch.west);

% Address in the middle between the two latches
\node[label] (addr) at ($(rowlatch.west)!0.5!(collatch.west) + (-3,0)$) {addr};
\coordinate (addr_split) at ($(rowlatch.west)!0.5!(collatch.west) + (-1.8,0)$);

\draw[signal, line width=2pt] (addr.east) -- (addr_split);
% Branch to row and column latches
\draw[signal, purple, line width=2pt] (addr_split) -- (addr_split |- rowlatch.west) -- (rowlatch.west);
\draw[signal, olive, line width=2pt] (addr_split) -- (addr_split |- collatch.west) -- (collatch.west);

% Clock symbol relative to addr_split
\drawclock{$(addr_split) + (-0.4,-0.75)$}

% Connections between blocks
\draw[signal, purple, line width=1.5pt] (rowlatch.east) -- node[above, font=\small\bfseries, purple] {row} (rowdecoder.west);
\draw[signal, olive, line width=1.5pt] (collatch.east) -- node[above, font=\small\bfseries, olive] {column} (coldecoder.west);

% Row decoder to memory array with highlighted row
\draw[signal, purple] (rowdecoder.east) -- (rowdecoder.east -| array_corner);
% Draw wordlines and highlight one
\foreach \y in {-0.3,-0.6,-0.9,-1.2,-1.5,-1.8,-2.1,-2.4} {
    \draw[purple, thick] ([yshift=\y cm]array_corner) -- ++(0.1,0);
}
% Highlight one row
\draw[purple, line width=2.5pt, opacity=0.5] ([yshift=-0.9cm]array_corner) -- ([xshift=4cm, yshift=-0.9cm]array_corner);

% Column decoder to memory array with highlighted column
\coordinate (array_bottom) at ([yshift=-2.7cm]array_corner);
\draw[signal, olive] (coldecoder.north) -- (coldecoder.north |- array_bottom);
% Draw bitlines and highlight one
\foreach \x in {0.6,1.2,1.8,2.4,3,3.6} {
    \draw[olive, thick] ([xshift=\x cm, yshift=-2.7cm]array_corner) -- ++(0,0.1);
}
% Highlight one column
\draw[olive, line width=2.5pt, opacity=0.5] ([xshift=2.1cm]array_corner) -- ([xshift=2.1cm, yshift=-2.7cm]array_corner);

% Mark intersection
\fill[red] ([xshift=2.1cm, yshift=-0.9cm]array_corner) circle (0.06);

% Data I/O - horizontal arrow
\draw[signal, blue, line width=2pt, <->] 
  (coldecoder.east) 
    -- node[midway, above, blue]{data} 
  ++(1,0);

% Clock symbol near data - relative to coldecoder
\drawclock{$(coldecoder.east) + (0.5,-0.3)$}

\node[
  align=center, 
  fill=white, 
  fill opacity=0.9,   % background 50% transparent
  text opacity=1,     % text fully visible
  inner sep=2pt
] at ([xshift=2cm, yshift=-1.35cm]array_corner) {memory\\[-2]array};

\end{tikzpicture}
\end{center}

\vspace{-0.2cm}
\textbf{DRAM access sequence:}
\begin{enumerate}
\item Row address on bus → Assert RAS$\#$ to latch row
\item Column address on bus → Assert CAS$\#$ to latch column (after t$_{RCD}$ delay)
\item Data available after CAS latency (CL)
\end{enumerate}

\end{frame}

% Slide: Page Mode DRAM
\begin{frame}{Page Mode DRAM}
\textbf{Allows multiple accesses to different columns within the same row}
\begin{itemize}
\item Saves RAS, RAS to CAS delay, and Row pre-charge
\end{itemize}

\vspace{-0.1cm}
\begin{center}
\begin{tikztimingtable}[
  timing/slope=0.2,
  timing/coldist=0.8cm,
  xscale=1.15,
  timing/rowdist=0.65cm,
  timing/name/.style={font=\small}
]
  RAS\# & 2H L 9L 6H 12.5L \\
  CAS\# & 5H L 2H L 2H L H 8H L 2H L 2H L 2.5H \\
  Addr  & U 1.5D{Row} 1.5U 1.5D{\colorbox{blue!30}{Col}} 1.5U 1.5D{\colorbox{red!30}{Col}} 1.5U 1.5D{\colorbox{orange!30}{Col}} 6U 1.5D{Row} 1.5U 1.5D{\colorbox{green!30}{Col}} 1.5U 1.5D{\colorbox{purple!30}{Col}} 1.5U 1.5D{\colorbox{cyan!30}{Col}} 2.5U \\
  Data  & 6U 2D{\colorbox{blue!30}{Data}} U 2D{\colorbox{red!30}{Data}} U 2D{\colorbox{orange!30}{Data}} 8.5U 2D{\colorbox{green!30}{Data}} U 2D{\colorbox{purple!30}{Data}} U 2D{\colorbox{cyan!30}{Data}} \\
  \extracode
    % Timing annotations
    \begin{scope}[>=stealth]
      %\draw[<->] (0.8,3.6) -- node[above,font=\scriptsize] {tRCD} (2.4,3.6);
      %\draw[<->] (5.6,3.6) -- node[above,font=\scriptsize] {tRP} (10.4,3.6);

      % CL
      \draw[dashed] (4.1,-7.5) -- node[below,font=\scriptsize] {} (4.1,-4);
      \draw[dashed] (6,-7.5) -- node[below,font=\scriptsize] {} (6.1,-5.5);
      \draw[<->] (4.1,-7.5) -- node[below,font=\scriptsize] {CL} (6.1,-7.5);

      % tRCD
      \draw[<->] (2.1,1.5) -- node[above,font=\scriptsize] {tRCD} (5,1.5);
      \draw[dashed] (2.1,1.5) -- node[below,font=\scriptsize] {} (2.1,0.5);
      \draw[dashed] (5,1.5) -- node[below,font=\scriptsize] {} (5,-1.5);
      
      % tRP
      \draw[<->] (12.1,1.5) -- node[above,font=\scriptsize] {tRP} (18,1.5);
      \draw[dashed] (12.1,1.5) -- node[below,font=\scriptsize] {} (12.1,0.5);
      \draw[dashed] (18.1,1.5) -- node[below,font=\scriptsize] {} (18.1,0.5);
    \end{scope}
\end{tikztimingtable}
\end{center}

\vspace{-0.4cm}
\begin{itemize}
\item \textbf{tRP}: Row pre-charge time (close current row, open new row)
\item \textbf{CL}: CAS latency (time from CAS to data available)
\item \textbf{Not true random access}: same-row access $\gg$ faster than different-row
\end{itemize}
\end{frame}

% Slide: Synchronous DRAM - SDRAM
\begin{frame}{Synchronous DRAM -- SDRAM}
\textbf{Clock-synchronized (100-200MHz)}
\begin{itemize}
\item All signals referenced to external clock; synchronizes with CPU timing
\end{itemize}

\vspace{0.15cm}
\textbf{4 banks -- multiple rows open simultaneously}
\begin{itemize}
\item One open row per bank; fast column access within 4 open rows
\item ACTIVE to new bank can be issued while accessing current bank
\end{itemize}

\vspace{0.15cm}
\textbf{Command-driven operation}
\begin{itemize}
\item ACTIVE: select bank + row
\item READ/WRITE: select column
\end{itemize}

\vspace{0.15cm}
\textbf{Burst-oriented access}
\begin{itemize}
\item Successive columns in same row; programmable length: 1, 2, 4, 8, full-page
\end{itemize}
\end{frame}

% Slide: SDRAM Features (continued)
\begin{frame}{SDRAM Features (continued)}
\textbf{Programmable Mode Register}
\begin{itemize}
\item CAS latency, burst length, burst type
\end{itemize}

\vspace{0.25cm}
\textbf{Auto pre-charge}: close row at last read/write in burst

\vspace{0.25cm}
\textbf{Auto refresh}: DRAM capacitors leak $\rightarrow$ periodic refresh needed
\begin{itemize}
\item Internal counters automatically generate refresh addresses
\end{itemize}

\vspace{0.3cm}
\begin{block}{Key Advantage}
Bank interleaving: while accessing one bank, another prepares its row $\rightarrow$ higher throughput
\end{block}
\end{frame}

% Slide: SDRAM Timing
\begin{frame}{SDRAM Timing}
\vspace{-0.2cm}
\begin{center}
\begin{tikztimingtable}[
  timing/slope=0.15,
  timing/coldist=0.35cm,
  xscale=1.7,
  timing/rowdist=0.6cm,
  timing/name/.style={font=\small}
]
  clock & L H L H L H L H L H L H L H L H L H L H L H L H L H \\
  cmd   & 2D{\textcolor{cyan}{ACT}} 2U 2D{\textcolor{cyan}{RD}} 2D{\textcolor{cyan}{RD+PC}} 2D{\textcolor{blue}{ACT}} 2U 2D{\textcolor{blue}{RD}} 2D{\textcolor{cyan}{ACT}} 2U 2D{\textcolor{cyan}{RD}} 2D{\textcolor{blue}{RD}} 4U \\
  \\
  Bank  & 2D{\textcolor{cyan}{Bank 0}} 2U 2D{\textcolor{cyan}{Bank 0}} 2D{\textcolor{cyan}{Bank 0}} 2D{\textcolor{blue}{Bank 1}} 2U 2D{\textcolor{blue}{Bank 1}} 2D{\textcolor{cyan}{Bank 0}} 2U 2D{\textcolor{cyan}{Bank 0}} 2D{\textcolor{blue}{Bank 1}} 4U \\
  Addr  & 2D{\textcolor{cyan}{Row i}} 2U 2D{\textcolor{cyan}{Col j }} 2D{\textcolor{cyan}{Col k }} 2D{\textcolor{blue}{Row m}} 2U 2D{\textcolor{blue}{Col n}} 2D{\textcolor{cyan}{Col l}} 2U 2D{\textcolor{cyan}{Col q}} 2D{\textcolor{blue}{Col n+1}} 4U \\
  \\
  Data  & 8U 2D{\textcolor{cyan!50}{Data j}} 2D{\textcolor{cyan!50}{Data k}} 4U 2D{\textcolor{blue}{Data n}} 4U 2D{\textcolor{cyan}{Data q}} 2D{\textcolor{blue}{Data n+1}} \\
  \extracode
    % Vertical grid lines
    \begin{scope}[gray!30, thin]
      \foreach \x in {0,2,...,24} {
        \draw[dashed] (\x+0.15,0.5) -- (\x+0.15,-12);
      }
    \end{scope}
    % Timing annotations
    \begin{scope}[>=stealth, font=\scriptsize]
      % tRCD
%      \draw[<->,thick] (0,3.8) -- node[above] {tRCD$>$20ns} (4*0.75,3.8);
      % tRC
%      \draw[<->,thick] (0,4.3) -- node[above] {tRC$>$70ns} (8*0.75,4.3);
      % tRRD
%      \draw[<->,thick] (8*0.75,3.8) -- node[above] {tRRD$>$20ns} (12*0.75,3.8);
      \draw[<->,thick] (9.15,-10) -- node[midway, fill=white, inner sep=1pt] {CL=2} (5.15,-10);
      \draw[--] (5.15,-10) -- (5.15,-8);
      \draw[--] (9.15,-10) -- (9.15,-11);

    \end{scope}
\end{tikztimingtable}
\end{center}

\vspace{-0.3cm}
\textbf{Key timing parameters:}
\begin{itemize}
\item \textbf{tRCD}: ACTIVE to READ/WRITE gap = $\lceil$tRCD(MIN) / clock period$\rceil$
\item \textbf{tRC}: Successive ACTIVE to different row in same bank
\item \textbf{tRRD}: Successive ACTIVE commands to different banks
\end{itemize}
\end{frame}

% Slide: DDR-SDRAM
\begin{frame}{DDR-SDRAM}
\textbf{2n-prefetch architecture - doubles data rate}

\vspace{0.2cm}
\begin{columns}[T]
\column{0.58\textwidth}
\textbf{How it works:}
\begin{itemize}
\item Internal DRAM cells clocked same speed as SDR SDRAM
\item Internal data bus is 2$\times$ width of external bus
\item Data capture twice per clock cycle:
  \begin{itemize}
  \item Lower half sampled at clock rise
  \item Upper half sampled at clock fall
  \end{itemize}
\item 200MHz clock $\rightarrow$ 400M transfers/sec
\end{itemize}

\vspace{0.2cm}
\textbf{Power:} 2.5V (vs. 3.3V in SDRAM)

\column{0.38\textwidth}
\vspace{0.2cm}
\begin{center}
\begin{tikzpicture}[scale=0.75, transform shape]
  % SDRAM Array
  \node[draw, thick, minimum width=2.5cm, minimum height=1.5cm, fill=blue!10, align=center] (array) at (0,0) {SDRAM\\Array};

  % Two multiplexers
  \node[draw, thick, trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=1cm, minimum height=0.6cm, fill=green!20] (mux1) at (3,0.4) {0:n-1};
  \node[draw, thick, trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=1cm, minimum height=0.6cm, fill=green!20] (mux2) at (3,-0.4) {n:2n-1};

  % Internal bus
  \draw[->, very thick] (array.east) -- node[above, font=\tiny] {0:2n-1} (1.5,0);
  \draw[->, thick] (1.5,0.4) -- (mux1.west);
  \draw[->, thick] (1.5,-0.4) -- (mux2.west);

  % Output
  \draw[->, very thick] (mux1.east) -- (4.5,0.4);
  \draw[->, very thick] (mux2.east) -- (4.5,-0.4);
  \draw[->, very thick] (4.5,0) -- node[above, font=\small] {0:n-1} (5.5,0);
  \node[right, font=\scriptsize] at (5.5,0.4) {400M};
  \node[right, font=\scriptsize] at (5.5,0) {xfer/sec};

  % Clock label
  \node[below, font=\tiny] at (0,-1.2) {200MHz clock};
\end{tikzpicture}
\end{center}
\end{columns}
\end{frame}

% Slide: DDR SDRAM Timing
\begin{frame}{DDR SDRAM Timing}
\vspace{-0.2cm}
\begin{center}
\begin{tikztimingtable}[
  timing/slope=0.15,
  timing/coldist=0.75cm,
  xscale=1,
  timing/rowdist=0.6cm,
  timing/name/.style={font=\small}
]
  200MHz clock & 26C \\
  cmd   & 2D{ACT} 4D{NOP} 2D{RD} 2D{NOP} 2D{ACT} 4D{NOP} 2D{RD} 2D{ACT} 4D{NOP} \\
  Bank  & 2D{\colorbox{cyan!30}{Bank 0}} 4D{X} 2D{\colorbox{cyan!30}{Bank 0}} 2D{X} 2D{\colorbox{cyan!30}{Bank 0}} 4D{X} 2D{\colorbox{cyan!30}{Bank 0}} 2D{\colorbox{blue!30}{Bank 1}} 4D{X} \\
  Addr  & 2D{\colorbox{cyan!30}{Row i}} 4D{X} 2D{\colorbox{cyan!30}{Col j}} 2D{X} 2D{\colorbox{cyan!30}{Row l}} 4D{X} 2D{\colorbox{cyan!30}{Col j}} 2D{\colorbox{blue!30}{Row m}} 4D{X} \\
  Data  & 12U 2D{j} 2D{+1} 2D{+2} 2D{+3} 2U 2D{n} 2D{+1} 2D{+2} 2D{+3} \\
  \extracode
    % Timing annotations
    \begin{scope}[>=stealth, font=\scriptsize]
      % tRCD
      \draw[<->,thick] (0,3.8) -- node[above] {tRCD$>$20ns} (6*0.75,3.8);
      % tRC
      \draw[<->,thick] (0,4.3) -- node[above] {tRC$>$70ns} (16*0.75,4.3);
      % tRRD
      \draw[<->,thick] (16*0.75,3.8) -- node[above] {tRRD$>$20ns} (22*0.75,3.8);
      % CL=2
      \draw[<->,thick] (6*0.75,-0.6) -- node[below] {CL=2} (12*0.75,-0.6);
    \end{scope}
\end{tikztimingtable}
\end{center}

\vspace{-0.2cm}
\textbf{DDR burst length = 4:} Each READ transfers 4 consecutive locations
\end{frame}

% Slide: DDR2
\begin{frame}{DDR2}
\textbf{DDR2 doubles bandwidth with 4-bit prefetch}

\vspace{0.2cm}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Key improvements:}
\begin{itemize}
\item \textbf{4-bit prefetch}: internally read/write 4$\times$ external bus width
\item DDR2-533 cell works at same frequency as DDR266 or PC133
\item Prefetching increases latency (trade-off)
\item \textbf{Smaller page}: 1KB vs. 2KB
  \begin{itemize}
  \item Reduces activation power
  \end{itemize}
\item \textbf{8 banks} in 1Gb+ densities
  \begin{itemize}
  \item Increases random access performance
  \end{itemize}
\end{itemize}

\column{0.48\textwidth}
\textbf{Power improvements:}
\begin{itemize}
\item 1.8V (vs 2.5V in DDR)
\item Significantly lower power
\end{itemize}

\vspace{0.3cm}
\textbf{Dual channel mode support}

\vspace{0.3cm}
\begin{center}
\begin{tikzpicture}[scale=0.6, transform shape]
  % SDRAM
  \node[draw, thick, minimum width=1.8cm, minimum height=0.6cm, fill=blue!10] at (0,2.5) {Memory Cell};
  \node[draw, thick, minimum width=1.2cm, minimum height=0.6cm, fill=green!20] at (2.2,2.5) {I/O Buffers};
  \draw[->, very thick] (2.8,2.5) -- (3.5,2.5) node[right, font=\tiny] {Data Bus};
  \node[left, font=\tiny] at (-0.9,2.2) {100 MHz};
  \node[above, font=\small] at (0,3.1) {\textbf{SDRAM}};

  % DDR I
  \node[draw, thick, minimum width=1.8cm, minimum height=0.6cm, fill=blue!10] at (0,1.5) {Memory Cell};
  \node[draw, thick, minimum width=1.2cm, minimum height=0.6cm, fill=green!20] at (2.2,1.5) {I/O Buffers};
  \draw[->, very thick] (2.8,1.5) -- (3.5,1.5) node[right, font=\tiny] {Data Bus};
  \node[left, font=\tiny] at (-0.9,1.2) {100 MHz};
  \node[above, font=\small] at (0,2.1) {\textbf{DDR I}};

  % DDR II
  \node[draw, thick, minimum width=1.8cm, minimum height=0.6cm, fill=blue!10] at (0,0.5) {Memory Cell};
  \node[draw, thick, minimum width=1.2cm, minimum height=0.6cm, fill=green!20] at (2.2,0.5) {I/O Buffers};
  \draw[->, very thick] (2.8,0.5) -- (3.5,0.5) node[right, font=\tiny] {Data Bus};
  \node[left, font=\tiny] at (-0.9,0.2) {100 MHz};
  \node[above, font=\small] at (0,1.1) {\textbf{DDR II}};
\end{tikzpicture}
\end{center}
\end{columns}
\end{frame}

% Slide: DDR Comparison
\begin{frame}{DDR Comparison}
\vspace{-0.2cm}
\begin{center}
\tiny
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
& \textbf{SDRAM} & \textbf{DDR} & \textbf{DDR2} & \textbf{DDR3} & \textbf{DDR4} & \textbf{DDR5} \\
\hline
\textbf{Introduced} & 1988 & 2000 & 2003 & 2007 & 2014 & 2021 \\
\hline
\textbf{Prefetch depth} & 1-Bit & 2-Bit & 4-Bit & 8-Bit & Per Bank & 16-Bit \\
\hline
\textbf{Internal clock (MHz)} & 100-166 & 133-200 & 133-200 & 133-200 & 133-200 & - \\
\hline
\textbf{Data Rate (MT/s)} & 100-166 & 266-400 & 533-800 & 1066-1600 & 2133-5100 & 3200-6400 \\
\hline
\textbf{Transfer Rate (GB/s)} & 0.8-1.3 & 2.1-3.2 & 4.2-6.4 & 8.5-14.9 & 17-25.6 & 38.4-51.2 \\
\hline
\textbf{Internal banks} & 4 & 4 & 4/8 & 8 & 16 & 32 \\
\hline
\textbf{Bank groups} & 1 & 1 & 1 & 1 & \textcolor{green!60!black}{4} & \textcolor{green!60!black}{4} \\
\hline
\textbf{Burst length} & 8 & 8 & 8 & 8 & 8 & \textcolor{blue}{16} \\
\hline
\textbf{Channels / DIMM} & 1 & 1 & 1 & 1 & 1 & \textcolor{blue}{2} \\
\hline
\textbf{Max DIMM size (GB)} & - & 1 & 4 & 16 & 64 & 256 \\
\hline
\textbf{Power mgmt} & On MB & On MB & On MB & On MB & On MB & \textcolor{green!60!black}{On DIMM} \\
\hline
\textbf{Voltage (V)} & 3.3 & 2.5-2.6 & 1.8 & 1.35-1.5 & 1.2 & 1.1 \\
\hline
\end{tabular}
\end{center}

\vspace{0.2cm}
\textbf{Trends:} Higher bandwidth, lower voltage, more banks, increased prefetch depth
\end{frame}

\section{Real System Examples}

% Slide: Real System Topology - Part 1
\begin{frame}{Real System Topology (Part 1)}
\begin{columns}[T]
\column{0.46\textwidth}
\begin{center}
\vspace{-8mm}
\includegraphics[width=\textwidth,height=0.85\textheight,keepaspectratio]{figures/topo.png}
\end{center}

\column{0.54\textwidth}
\textbf{1. Two-Socket NUMA System}
\begin{itemize}
\item 2 Packages (CPU sockets)
\item 2 NUMA nodes (125GB + 126GB)
\item Each package: 28 cores
\item Total: 56 physical cores
\end{itemize}

\vspace{0.5cm}
\textbf{2. Hyperthreading (SMT)}
\begin{itemize}
\item Each core has 2 PUs (processing units)
\item PU = hardware thread
\item Total: 112 logical processors
\item PU IDs interleaved\\(P\#0, P\#56, P\#2, P\#58...)
\end{itemize}
\end{columns}
\end{frame}

% Slide: Real System Topology - Part 2
\begin{frame}{Real System Topology (Part 2)}
\begin{columns}[T]
\column{0.46\textwidth}
\begin{center}
\vspace{-8mm}
\includegraphics[width=\textwidth,height=0.85\textheight,keepaspectratio]{figures/topo.png}
\end{center}

\column{0.54\textwidth}
\textbf{3. Cache Hierarchy}
\begin{itemize}
\item \textcolor{red}{Private} per core:
  \begin{itemize}
  \item L1i: 32KB (instruction)
  \item L1d: 48KB (data)
  \item L2: 2MB
  \end{itemize}
\item \textcolor{blue}{Shared} per package:
  \begin{itemize}
  \item L3: 53MB (all 28 cores)
  \end{itemize}
\end{itemize}

\vspace{0.5cm}
\textbf{4. I/O Device Locality}
\begin{itemize}
\item PCI devices attached to specific packages
\item Package 0: Ethernet, VGA, SATA, RAID
\item Package 1: High-speed Ethernet (mlx5)
\item Accessing devices $\rightarrow$ prefer local memory!
\end{itemize}

\vspace{0.3cm}
\textbf{Tip:} Pin network threads to Package 1 cores for best mlx5 performance!
\end{columns}
\end{frame}

\section{PCIe Architecture}

% Slide: PCIe Overview
\begin{frame}{PCIe: PCI Express}
\textbf{PCIe is a layered protocol}

\begin{itemize}
\item \textbf{Compatible with the PCI addressing model}
  \begin{itemize}
  \item All existing applications and drivers operate unchanged
  \end{itemize}

\vspace{0.3cm}
\item \textbf{Software layers} generate read and write requests

\vspace{0.3cm}
\item \textbf{Hardware layers} process and transmit data:
  \begin{itemize}
  \item \textcolor{blue}{Transaction Layer}: Splits data to packets
  \item \textcolor{green!60!black}{Data Link Layer}: Ensures data integrity (adds sequence numbers and CRC)
  \item \textcolor{orange}{Physical Layer}: Transmits the packets (connector, voltage levels, etc.)
  \end{itemize}
\end{itemize}

\vspace{0.3cm}
\begin{alertblock}{Key Benefit}
Layered design ensures reliable delivery of packets across the PCIe link
\end{alertblock}
\end{frame}

% Slide: PCIe Layer Architecture with Diagram
\begin{frame}{PCIe Layer Architecture}
\begin{center}
\begin{tikzpicture}[scale=0.9,
    box/.style={draw, thick, minimum height=1cm, align=center, font=\footnotesize},
    layer/.style={draw=none, align=center, font=\footnotesize}
]

% Top level - Original packet
\node[box, fill=blue!10, minimum width=1.5cm] (header) at (0,0) {Header};
\node[box, fill=blue!5, minimum width=3cm, anchor=west] (data) at (header.east) {Data};



% T-Layer Packet - below header, spanning from header.west to data.east
\node[box, fill=blue!20, anchor=north west, minimum width=4.5cm] (tlpacket) at ([yshift=-6mm]header.south west) {T-Layer Packet};

% Dashed lines showing T-Layer includes header and data
\draw[dashed, thick] (header.south west) -- (tlpacket.north west);
\draw[dashed, thick] (data.south east) -- (tlpacket.north east);

% Packet Sequence Number - left of T-Layer Packet, wider and exactly 2 rows
\node[box, fill=cyan!30, minimum width=2.8cm, anchor=east] (pseq) at (tlpacket.west) {Packet Sequence\\Number};

% CRC - right of T-Layer Packet, adjacent
\node[box, fill=cyan!30, minimum width=1cm, anchor=west] (crc1) at (tlpacket.east) {CRC};


% L-Layer Packet - below pseq, spanning from pseq.west to crc1.east
\node[box, fill=cyan!20, minimum width=8.3cm, anchor=north west] (llpacket) at ([yshift=-6mm]pseq.south west) {L-Layer Packet};

% Dashed lines showing L-Layer includes pseq, tlpacket, and crc1
\draw[dashed, thick] (pseq.south west) -- (llpacket.north west);
\draw[dashed, thick] (crc1.south east) -- (llpacket.north east);

% Frame boxes - left and right of L-Layer Packet, touching
\node[box, fill=orange!30, minimum width=1cm, anchor=east] (frame1) at (llpacket.west) {Frame};
\node[box, fill=orange!30, minimum width=1cm, anchor=west] (frame2) at (llpacket.east) {Frame};

% Physical Layer label - positioned similarly
\node[layer, right=of frame2] (physlayer) {\textbf{Physical Layer}};
\node[layer, anchor=east] (linklayer) at (crc1 -| physlayer.east) {\textbf{Link Layer}};
\node[layer, anchor=east] (translayer) at (data -| physlayer.east) {\textbf{Transaction Layer}};

% Dashed line separator below
\draw[dashed, thick] ([yshift=-3mm,xshift=-1.5cm]header.south -| pseq.west) -- ([yshift=-3mm]translayer.east |- header.south);
\draw[dashed, thick] ([yshift=-3mm,xshift=-1.5cm]pseq.south west) -- ([yshift=-3mm]linklayer.east |- pseq.south);

% Arrows between layers
\draw[<->, thick] (linklayer.south) -- (physlayer.north -| linklayer);
\draw[<->, thick] (linklayer.north) -- (translayer.south -| linklayer);

\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\footnotesize
Data flows top-to-bottom (TX) and bottom-to-top (RX) through the layers
\end{frame}

% Slide: Physical Layer
\begin{frame}{PCIe Physical Layer}
\textbf{Responsibilities:}
\begin{itemize}
\item \textbf{Transmits packets} received from the Data Link Layer
\item \textbf{Connector definition}: Physical form factor and pinout
\item \textbf{Electrical specifications}: Voltage levels, timing, signaling
\item \textbf{Serialization/Deserialization}: Converts parallel data to serial transmission
\end{itemize}

\vspace{0.3cm}
\textbf{Key Features:}
\begin{itemize}
\item Point-to-point serial links (lanes)
\item Multiple lanes can be aggregated: x1, x4, x8, x16
\item High-speed differential signaling
\item Supports multiple generations (PCIe 4.0: 16 GT/s, PCIe 5.0: 32 GT/s)
\end{itemize}

\vspace{0.3cm}
\begin{alertblock}{Physical Layer Goal}
Reliable transmission of bits across the physical medium
\end{alertblock}
\end{frame}

% Slide: Data Link Layer
\begin{frame}{PCIe Data Link Layer}
\textbf{Responsibilities:}
\begin{itemize}
\item \textbf{Ensure data integrity}: Adds sequence number and CRC to each transaction layer packet
\item \textbf{Credit-based flow control protocol}
\item \textbf{Automatic retry} of corrupted packets detected by CRC checking
\end{itemize}

\vspace{0.3cm}
\textbf{Flow Control:}
\begin{itemize}
\item Packets only transmitted when receiver has buffer space available
\item \textcolor{green!60!black}{Eliminates packet retries due to buffer overflow}
\item \textcolor{green!60!black}{Saves bus bandwidth} (no wasted transmission attempts)
\end{itemize}

\vspace{0.3cm}
\textbf{Error Handling:}
\begin{itemize}
\item CRC checks data integrity
\item NAK (Negative Acknowledgment) triggers automatic retransmission
\item Transparent to upper layers
\end{itemize}
\end{frame}

% Slide: Transaction Layer
\begin{frame}{PCIe Transaction Layer}
\textbf{Responsibilities:}
\begin{itemize}
\item \textbf{Receives} read and write requests from the software layer
\item \textbf{Creates} request packets for transmission to the link layer
\item \textbf{Receives} response packets from the link layer
\item \textbf{Matches} responses with original requests using unique identifiers
\end{itemize}

\vspace{0.3cm}
\textbf{Packet Format Features:}
\begin{itemize}
\item Supports 32-bit and extended 64-bit memory addressing
\item Packet attributes for optimization:
  \begin{itemize}
  \item ``no-snoop'': Skip cache coherency checks
  \item ``relaxed-ordering'': Allow out-of-order completion
  \item ``priority'': QoS support
  \end{itemize}
\end{itemize}

\vspace{0.3cm}
\textbf{Some request packets require a response packet}
\end{frame}

% Slide: PCIe Address Spaces
\begin{frame}{PCIe Address Spaces and Message Space}
\textbf{PCIe supports three address spaces + Message Space:}

\vspace{0.3cm}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Three PCI address spaces:}
\begin{enumerate}
\item \textbf{Memory Space}
  \begin{itemize}
  \item 32-bit or 64-bit addressing
  \item DMA access
  \end{itemize}
\item \textbf{I/O Space}
  \begin{itemize}
  \item Legacy support
  \item 32-bit addressing
  \end{itemize}
\item \textbf{Configuration Space}
  \begin{itemize}
  \item Device enumeration
  \item Capability discovery
  \end{itemize}
\end{enumerate}

\column{0.5\textwidth}
\textbf{Message Space} (not an address space):
\begin{itemize}
\item Virtual wires mechanism
\item Eliminates hard-wired sideband signals used in PCI
\item Examples:
  \begin{itemize}
  \item Interrupts (MSI/MSI-X)
  \item Power management requests
  \item Reset signals
  \item Error reporting
  \end{itemize}
\end{itemize}

\vspace{0.5cm}
\textbf{Message Signaled Interrupt (MSI)}
\begin{itemize}
\item Propagates system interrupts via memory writes
\item More efficient than legacy INTx
\end{itemize}
\end{columns}
\end{frame}

\section{System Boot Process}

% Slide: Boot Process Overview
\begin{frame}{System Boot Process Overview}
\textbf{Upon computer power-on, a sequence of events occurs:}

\begin{enumerate}
\item \textbf{CPU Reset}
  \begin{itemize}
  \item CPU wakes up and exits reset sequence
  \item Jumps to firmware entry point
  \end{itemize}

\vspace{0.2cm}
\item \textbf{Firmware Initialization} (UEFI/BIOS)
  \begin{itemize}
  \item Power-On Self-Test (POST)
  \item Hardware enumeration and initialization
  \end{itemize}

\vspace{0.2cm}
\item \textbf{Boot Loader}
  \begin{itemize}
  \item Firmware locates and loads boot loader
  \item Boot loader prepares system for OS
  \end{itemize}

\vspace{0.2cm}
\item \textbf{Operating System Load}
  \begin{itemize}
  \item OS kernel loaded into memory
  \item Device drivers and system services initialized
  \end{itemize}
\end{enumerate}
\end{frame}

% Slide: UEFI
\begin{frame}{UEFI: Modern Firmware Interface}
\textbf{UEFI (Unified Extensible Firmware Interface)}

\vspace{0.3cm}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Key Features:}
\begin{itemize}
\item Modular architecture
\item Supports GPT partitions
\item Secure Boot capability
\item 64-bit addressing
\item Network boot support
\item Faster boot times
\end{itemize}

\column{0.48\textwidth}
\textbf{Responsibilities:}
\begin{itemize}
\item Hardware initialization
\item POST execution
\item Boot device selection
\item Load boot loader
\item \textcolor{blue!70!black}{Provide hardware info to OS}
\end{itemize}
\end{columns}

\vspace{0.5cm}
\begin{block}{Hardware Discovery}
UEFI prepares hardware description tables for the operating system to discover available devices and their configuration
\end{block}
\end{frame}

% Slide: POST and Hardware Initialization
\begin{frame}{Power-On Self-Test (POST) and Initialization}
\textbf{Firmware performs POST to verify hardware:}

\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Hardware Tests:}
\begin{itemize}
\item CPU functionality
\item Memory (DRAM) test
\item Chipset registers
\item Storage controllers
\item Keyboard/input devices
\item Serial/parallel ports
\item Display adapter
\end{itemize}

\column{0.5\textwidth}
\textbf{Initialization Tasks:}
\begin{itemize}
\item Initialize power management
\item Configure PCIe devices
\item Set up interrupt controllers
\item Initialize memory controller
\item Apply CPU microcode patches
\item Read system configuration
\item Display system summary
\end{itemize}
\end{columns}

\vspace{0.3cm}
\begin{alertblock}{Microcode Updates}
Firmware may contain CPU microcode patches to fix hardware bugs before OS loads
\end{alertblock}
\end{frame}

% Slide: Boot Device Selection and OS Load
\begin{frame}{Boot Device Selection and OS Loading}
\textbf{After POST completes:}

\vspace{0.3cm}
\textbf{1. Boot Device Selection}
\begin{itemize}
\item Firmware searches for bootable devices in priority order
\item Common boot order: NVMe/SSD, USB, Network (PXE), DVD
\item UEFI looks for EFI System Partition (ESP) with boot loaders
\end{itemize}

\vspace{0.3cm}
\textbf{2. Boot Loader Execution}
\begin{itemize}
\item Firmware loads and executes boot loader (e.g., GRUB, Windows Boot Manager)
\item Boot loader reads configuration and presents OS selection menu
\item Loads OS kernel into memory
\end{itemize}

\vspace{0.3cm}
\textbf{3. Operating System Initialization}
\begin{itemize}
\item OS kernel takes control from boot loader
\item Loads device drivers and system services
\item Mounts file systems
\item Starts user-space processes
\end{itemize}
\end{frame}

% New section: Device Discovery
\section{Hardware Discovery}

% Slide: Device Discovery Overview
\begin{frame}{Hardware Discovery: How OS Learns About Hardware}
\textbf{Problem:} OS needs to know what hardware is present
\begin{itemize}
\item Which devices are available?
\item Where are they located (addresses)?
\item What are their capabilities?
\item How to configure them?
\end{itemize}

\vspace{0.5cm}
\textbf{Two main approaches:}

\begin{columns}[T]
\column{0.48\textwidth}
\begin{block}{ACPI (x86)}
Advanced Configuration and Power Interface\\
\textcolor{blue!70!black}{Tables in memory}
\end{block}

\column{0.48\textwidth}
\begin{block}{Device Tree (ARM/Embedded)}
Flattened Device Tree (FDT)\\
\textcolor{green!60!black}{Data structure describing hardware}
\end{block}
\end{columns}
\end{frame}

% Slide: ACPI
\begin{frame}{ACPI: x86 Hardware Discovery}
\textbf{ACPI (Advanced Configuration and Power Interface)}

\vspace{0.3cm}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{What it provides:}
\begin{itemize}
\item CPU topology and features
\item Memory map
\item Interrupt routing (APIC/IOAPIC)
\item PCIe configuration
\item Power management info
\item Thermal management
\item Device configuration
\end{itemize}

\column{0.48\textwidth}
\textbf{How it works:}
\begin{itemize}
\item Firmware creates ACPI tables
\item Tables stored in memory
\item Pointer passed to OS
\item OS parses tables at boot
\item Dynamic discovery via ACPI methods
\end{itemize}
\end{columns}

\vspace{0.3cm}
\begin{alertblock}{ACPI Tables}
Examples: MADT (interrupts), SRAT (NUMA), DSDT (device description), MCFG (PCIe config)
\end{alertblock}
\end{frame}

% Slide: Device Tree
\begin{frame}{Device Tree: ARM/Embedded Hardware Discovery}
\textbf{Device Tree (Flattened Device Tree - FDT)}

\vspace{0.3cm}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{What it provides:}
\begin{itemize}
\item CPU cores and clusters
\item Memory regions
\item Bus topology
\item Device addresses
\item Interrupt connections
\item Clock sources
\item Pin configurations
\end{itemize}

\column{0.48\textwidth}
\textbf{How it works:}
\begin{itemize}
\item Tree structure describing HW
\item Compiled from .dts source
\item Bootloader passes to kernel
\item OS traverses tree at boot
\item Static description
\end{itemize}
\end{columns}

\vspace{0.3cm}
\begin{alertblock}{Device Tree Blob (DTB)}
Binary representation of hardware topology, typically loaded from flash or passed by bootloader
\end{alertblock}
\end{frame}

% Slide: ACPI vs Device Tree Comparison
\begin{frame}{ACPI vs Device Tree: Key Differences}
\begin{center}
\begin{tabular}{|p{2.8cm}|p{4.8cm}|p{4.8cm}|}
\hline
\textbf{Aspect} & \textbf{ACPI (x86)} & \textbf{Device Tree (ARM)} \\
\hline
\textbf{Architecture} & x86/x86\_64 primarily & ARM, RISC-V, embedded \\
\hline
\textbf{Discovery} & Dynamic + Static tables & Mostly static tree \\
\hline
\textbf{Complexity} & Complex, many features & Simpler, HW description \\
\hline
\textbf{Power Mgmt} & Extensive ACPI power states & Often separate driver \\
\hline
\textbf{Hotplug} & Well supported & Limited support \\
\hline
\textbf{Source} & Created by firmware & Pre-compiled or firmware \\
\hline
\textbf{Standardization} & ACPI spec by UEFI Forum & Open standard by Linaro \\
\hline
\end{tabular}
\end{center}

\vspace{0.3cm}
\textbf{Both solve the same problem:} Tell the OS what hardware exists and how to use it
\end{frame}

\section{Storage Media}

% Slide: Storage Hierarchy
\begin{frame}{Storage Media Hierarchy}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Storage Type} & \textbf{Typical Latency} & \textbf{Capacity} & \textbf{Volatile} \\
\hline
\textbf{DRAM} & 50-100 ns & GB & Yes \\
\hline
\textbf{NVMe SSD} & 10-100 $\mu$s & TB & No \\
\hline
\textbf{SATA SSD} & 50-150 $\mu$s & TB & No \\
\hline
\textbf{HDD} & 5-10 ms & TB & No \\
\hline
\textbf{Tape} & seconds & PB & No \\
\hline
\end{tabular}
\end{center}

\vspace{0.3cm}
\textbf{Key characteristics:}
\begin{itemize}
\item \textbf{Latency}: Access time increases dramatically down the hierarchy
\item \textbf{Capacity}: Storage capacity increases down the hierarchy
\item \textbf{Cost per byte}: Decreases down the hierarchy
\item \textbf{Bandwidth}: Generally decreases down the hierarchy
\item \textbf{Endurance}: Flash has limited write cycles (1K-100K); DRAM/HDD/Tape unlimited
\end{itemize}
\end{frame}

% Slide: HDD vs SSD
\begin{frame}{HDD vs SSD}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{HDD (Hard Disk Drive)}
\begin{itemize}
\item Mechanical spinning platters
\item Magnetic storage
\item Sequential read: 100-200 MB/s
\item Random access: 5-10 ms
\item Moving parts $\rightarrow$ fragile
\item Cheaper per GB
\item Limited IOPS ($\sim$100-200)
\end{itemize}

\column{0.48\textwidth}
\textbf{SSD (Solid State Drive)}
\begin{itemize}
\item NAND flash memory
\item Electronic storage
\item Sequential read: 500-7000 MB/s
\item Random access: 10-100 $\mu$s
\item No moving parts
\item More expensive per GB
\item High IOPS ($\sim$100K-1M)
\item Write endurance limit
\end{itemize}
\end{columns}

\vspace{0.3cm}
\textbf{SSDs dominate modern systems} due to performance advantages
\end{frame}

% Slide: Flash Memory Types
\begin{frame}{Flash Memory: SLC/MLC/TLC/QLC}
\textbf{NAND flash stores multiple bits per cell using voltage levels}

\vspace{0.15cm}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Type} & \textbf{Bits/Cell} & \textbf{Voltage Levels} & \textbf{Endurance} & \textbf{Performance} & \textbf{Cost} \\
\hline
\textbf{SLC} & 1 & $2^1 = 2$ & \textcolor{green!60!black}{100K} & \textcolor{green!60!black}{Fastest} & \textcolor{red}{Highest} \\
\hline
\textbf{MLC} & 2 & $2^2 = 4$ & 10K & Fast & High \\
\hline
\textbf{TLC} & 3 & $2^3 = 8$ & 3K & Medium & Medium \\
\hline
\textbf{QLC} & 4 & $2^4 = 16$ & \textcolor{red}{1K} & \textcolor{red}{Slower} & \textcolor{green!60!black}{Lowest} \\
\hline
\end{tabular}
\end{center}

\vspace{0.25cm}
\textbf{Key insight:} Voltage levels grow exponentially: $2^n$ levels for $n$ bits
\begin{itemize}
\item More levels $\rightarrow$ smaller voltage margins $\rightarrow$ harder to distinguish
\item Smaller margins $\rightarrow$ lower endurance, slower writes, more errors
\end{itemize}

\vspace{0.2cm}
\textbf{Applications:}
\begin{itemize}
\item \textbf{SLC}: Enterprise, high-performance \quad \textbf{TLC/QLC}: Consumer, cost-sensitive
\end{itemize}
\end{frame}

% Slide: NVMe vs SATA
\begin{frame}{Storage Interfaces: NVMe vs SATA}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{SATA (Serial ATA)}
\begin{itemize}
\item Legacy interface for HDDs
\item SATA III: 6 Gb/s ($\sim$600 MB/s)
\item Single queue, 32 commands
\item Higher latency overhead
\item Designed for spinning disks
\end{itemize}

\column{0.48\textwidth}
\textbf{NVMe (NVM Express)}
\begin{itemize}
\item PCIe-based interface
\item PCIe 4.0 x4: 64 Gb/s ($\sim$7 GB/s)
\item 64K queues, 64K commands each
\item Low latency, optimized for flash
\item Parallelism for high IOPS
\end{itemize}
\end{columns}

\vspace{0.4cm}
\begin{block}{NVMe Advantage}
NVMe reduces CPU overhead and latency by using PCIe directly instead of SATA controller, enabling full flash performance
\end{block}
\end{frame}


\end{document}